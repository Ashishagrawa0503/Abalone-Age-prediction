{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2645886,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook256f767315",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishagrawa0503/Abalone-Age-prediction/blob/main/notebook256f767315.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "#pillow pli ek library hai jo python ka jo image preprocessig m help krta hai\n",
        "\n",
        "\n",
        "#pillow pli ek library hai jo python ka jo image preprocessig m help krta hai\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "#images ko load krne ke liye load images ka upyog liya gya hai\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle dataset download -d masoudnickparvar/brain-tumor-mri-dataset\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/brain-tumor-mri-dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content\")\n",
        "zip_ref.close()\n",
        "train_dir=\"/content/Training\"\n",
        "test_dir=\"/content/Testing\"\n",
        "train_paths=[]\n",
        "train_labels=[]\n",
        "for label in os.listdir(train_dir):\n",
        "  for image in os.listdir(os.path.join(train_dir,label)):#os.listdir(path) is a function from the os\n",
        "  # module that returns a list containing the names of the entries in the directory given by path\n",
        "    train_paths.append(os.path.join(train_dir,label,image))\n",
        "    train_labels.append(label)\n",
        "\n",
        "train_paths,train_labels=shuffle(train_paths,train_labels)\n",
        "#image preprocessing\n",
        "#-------------------\n",
        "\n",
        "#image augmantation\n",
        "def augemnt_image(image):\n",
        "  image = Image.fromarray(np.uint8(image))#image ko pahle unsigned integer mai convert kiyafir Image.fromarry pillow fuchion\n",
        "  #hai jiske help se image ko pillow formate main convert kiya kyoke hamne image enhancer pillow ka liya hua hai or wo pilow fatmate m image leta hai\n",
        "  image=ImageEnhance.Brightness(image).enhance(random.uniform(0.8,1.2))\n",
        "  #ImageEnhancer ke handar Brightness  call kiya or image diya fir is image ko enhance kiya par enhance karne k liye koi\n",
        "  #ratio baatana padega is liye random uniform ka upyog kiya matlb image ka enhancement 0.80se 1.2ke beach mai rakhna hai\n",
        "  #yadi image jo diya hai uske value 1.0 se aadhik hai to uske brightness kam krdo or yado 1.0 se less hai to image ke brightness badha do\n",
        "  image=ImageEnhance.Contrast(image).enhance(random.uniform(0.8,1.2))\n",
        "  image=ImageEnhance.Sharpness(image).enhance(random.uniform(0.8,1.2))\n",
        "  image= np.array(image)/255.0\n",
        "  #image ko pahle normalize kiya 0se 1 ke beach mai fr usko pillow formate se numpy formate mai convert kiya\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "#load image and apply augmentation\n",
        "def open_images(paths):\n",
        "  images = []\n",
        "  for path in (paths):\n",
        "    img= load_img(path,target_size(IMAGE_SIZE,IMAGE_SIZE))#SKlearn ka load image wala function jisko upper import kia hai\n",
        "    img = augemnt_image(img)\n",
        "    images.append(img)\n",
        "  return np.array(images)# is images ke andar har pixel ka value hoge\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#convert label name into integers\n",
        "def encoder_label(labels):\n",
        "  labels = os.listdir(train_dir)# jo 4 class the trasin dir ke andar usko 1,2,3,4 se encode kiya hai\n",
        "  encoder = [labels.index(label) for label in labels]\n",
        "  return encoder\n",
        "\n",
        "\n",
        "#data generater for batching\n",
        "def datagen(paths,labels,batch_size=12,epochs=1):\n",
        "  for _ in range(epochs):\n",
        "    for i in range(0,len(paths),batch_size):\n",
        "      batch_paths = paths[i:i+batch_size]\n",
        "      batch_labels = labels[i:i+batch_size]\n",
        "      batch_images = open_images(batch_paths)\n",
        "      batch_labels = encoder_label(batch_labels)\n",
        "      yield batch_images,batch_labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TYR5w-z1ULqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ],
      "metadata": {
        "id": "VFtODxScY0V_",
        "outputId": "ca0d5a43-3a91-40ab-f7ff-ec56a3bc90e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 75% 112M/149M [00:00<00:00, 1.16GB/s]\n",
            "100% 149M/149M [00:00<00:00, 982MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2Kepsw5Ch4n",
        "outputId": "dbdd70f0-cc63-49eb-ad87-ceeb3b0d26e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE=128\n",
        "base_model=VGG16(weights=\"imagenet\",include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))#(128*128 and RGB color)\n",
        "#imagenet data ke liye jo weights the wo hamre model m be use ho\n",
        "\n",
        "\n",
        "#freeze all layersof VGG16 base model(is model ke jitne be cnn rnn subko false kiya )\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "#set only last few layers(unfreeze some layers )\n",
        "\n",
        "base_model.layers[-2].trainable=True\n",
        "base_model.layers[-3].trainable=True\n",
        "base_model.layers[-4].trainable=True\n",
        "\n",
        "\n",
        "#bildmodel\n",
        "model=Sequential()\n",
        "model.add(Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3)))#input layer and add VGG16\n",
        "model.add(base_model)#image ka output multi dimension hoga is liye usko flatten kiya\n",
        "model.add(Flatten)\n",
        "model.(Dropout(0.3))\n",
        "model.add(Dense(128,activation=\"relu\"))#fully connection layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(os.listdir(train_dir)),activation=\"softmax\"))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "#parameters\n",
        "batch_size=20\n",
        "steps=int(len(train_paths)/batch_size)\n",
        "epochs=3\n",
        "\n",
        "#train model\n",
        "history=model.fit(\n",
        "    datagen(train_paths,train_labels,batch_size=batch_size,epochs=epochs),\n",
        "    steps_per_epoch=steps,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ip4_7kLRbb_I",
        "outputId": "9da8df93-6261-49bc-c3a8-0f24c7dbe0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-8-f831e7395077>, line 22)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-f831e7395077>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    model.(Dropout(0.3))\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhtfRa84CNfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}